{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils as ut\n",
    "early_stopping = ut.EarlyStopping(patience=100, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Create Data for Toy Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f388ecfa048>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD8CAYAAACfF6SlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3890d387b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sin(x, T=100):\n",
    "    return np.sin(2.0 * np.pi * x/T)\n",
    "\n",
    "def toy_problem(T=100, ampl=0.05):\n",
    "    x = np.arange(0, 2*T + 1)\n",
    "    noise = ampl*np.random.uniform(low = -1.0, high = 1.0, size=len(x))\n",
    "    return sin(x) + noise\n",
    "\n",
    "T = 100\n",
    "f = toy_problem(T)\n",
    "plt.plot(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2a. Prepare Input Data to Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_of_sequences = 2*T\n",
    "maxlen = 25\n",
    "data = []\n",
    "target = []\n",
    "\n",
    "for i in range(0, length_of_sequences - maxlen + 1):\n",
    "    data.append(f[i: i + maxlen])\n",
    "    target.append(f[i + maxlen])\n",
    "\n",
    "X = np.array(data).reshape(len(data), maxlen, 1)\n",
    "Y = np.array(target).reshape(len(data), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2b. Split Data into Training and Valdiation Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_train = int(len(data) * 0.9)\n",
    "N_validation = len(data) - N_train\n",
    "X_train, X_validation, Y_train, Y_validation = \\\n",
    "train_test_split(X, Y, test_size=N_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape, name=None):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.01) # resample 2 sd vals\n",
    "    return tf.Variable(initial, name=name)\n",
    "    \n",
    "def bias_variable(shape, name=None):\n",
    "    initial = tf.zeros(shape, dtype=tf.float32)\n",
    "    return tf.Variable(initial, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_Manual(x, n_batch, maxlen=None, n_hidden=None, n_out=None, \n",
    "                     n_in=None):\n",
    "    # define all our variables\n",
    "    V = weight_variable([n_hidden, n_out])\n",
    "    U = weight_variable([n_in, n_hidden]) # going to combine this as (x, U)\n",
    "    W = weight_variable([n_hidden, n_hidden])\n",
    "    b = bias_variable([n_hidden])\n",
    "    c = bias_variable([n_out])\n",
    "    \n",
    "    with tf.variable_scope('RNN'):\n",
    "        hlist = []\n",
    "        h_prev = tf.zeros([n_batch, n_hidden], dtype=tf.float32)\n",
    "        for t in range(maxlen):\n",
    "            if t > 0:\n",
    "                tf.get_variable_scope().reuse_variables()\n",
    "                h_prev = hlist[-1]\n",
    "            h_i = tf.tanh(tf.matmul(x[:, t, :], U) + tf.matmul(h_prev, W) + b)\n",
    "            hlist.append(h_i)\n",
    "    h_last = hlist[-1]\n",
    "    y = tf.matmul(h_last, V) + c\n",
    "    return y, [V, U, W, c, b]\n",
    "\n",
    "def loss(y, t):\n",
    "    mse = tf.reduce_mean(tf.square(y - t))\n",
    "    return mse\n",
    "\n",
    "def training(loss):\n",
    "    optimize = tf.train.AdamOptimizer(learning_rate = 0.001, beta1=0.9, beta2=0.999)\n",
    "    train_step = optimize.minimize(loss)\n",
    "    return train_step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Define TF Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimension 0 in both shapes must be equal, but are 1 and 20\n\tFrom merging shape 3 with other shapes. for 'sub/x/1' (op: 'Pack') with input shapes: [20,1], [1,20], [20,20], [1], [20].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    685\u001b[0m           \u001b[0mgraph_def_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_def_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m           input_tensors_as_shapes, status)\n\u001b[0m\u001b[1;32m    687\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Dimension 0 in both shapes must be equal, but are 1 and 20\n\tFrom merging shape 3 with other shapes. for 'sub/x/1' (op: 'Pack') with input shapes: [20,1], [1,20], [20,20], [1], [20].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-43d910142bd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m y = inference_Manual(x, n_batch, maxlen=maxlen, n_hidden=n_hidden, n_out= n_out,\n\u001b[1;32m     13\u001b[0m                     n_in=n_in)\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mtrain_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-0cc95ecd725e>\u001b[0m in \u001b[0;36mloss\u001b[0;34m(y, t)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mr_binary_op_wrapper\u001b[0;34m(y, x)\u001b[0m\n\u001b[1;32m    907\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mr_binary_op_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, preferred_dtype)\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 836\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx)\u001b[0m\n\u001b[1;32m    924\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_autopacking_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    968\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0minferred_dtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_autopacking_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minferred_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"packed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_autopacking_helper\u001b[0;34m(list_or_tuple, dtype, name)\u001b[0m\n\u001b[1;32m    914\u001b[0m         \u001b[0mmust_pack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m         \u001b[0mconverted_elem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_autopacking_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dense_tensor_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverted_elem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m           \u001b[0mmust_pack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_autopacking_helper\u001b[0;34m(list_or_tuple, dtype, name)\u001b[0m\n\u001b[1;32m    931\u001b[0m           elems_as_tensors.append(\n\u001b[1;32m    932\u001b[0m               constant_op.constant(elem, dtype=dtype, name=str(i)))\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melems_as_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_elems\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36m_pack\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   2870\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_graph_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2871\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m-> 2872\u001b[0;31m         \"Pack\", values=values, axis=axis, name=name)\n\u001b[0m\u001b[1;32m   2873\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2874\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2956\u001b[0m         op_def=op_def)\n\u001b[1;32m   2957\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2958\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2959\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2960\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   2207\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2209\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2210\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2211\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   2157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2158\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2159\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2161\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, require_shape_fn)\u001b[0m\n\u001b[1;32m    625\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[1;32m    626\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m                                   require_shape_fn)\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    689\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimension 0 in both shapes must be equal, but are 1 and 20\n\tFrom merging shape 3 with other shapes. for 'sub/x/1' (op: 'Pack') with input shapes: [20,1], [1,20], [20,20], [1], [20]."
     ]
    }
   ],
   "source": [
    "n_in = 1\n",
    "n_hidden = 20\n",
    "n_out = 1\n",
    "\n",
    "tf.reset_default_graph()\n",
    "# Input Parameters\n",
    "x = tf.placeholder(tf.float32, shape=[None, maxlen, n_in])\n",
    "t = tf.placeholder(tf.float32, shape=[None, n_out])\n",
    "n_batch = tf.placeholder(tf.int32, [])\n",
    "\n",
    "# TF Variables\n",
    "y = inference_Manual(x, n_batch, maxlen=maxlen, n_hidden=n_hidden, n_out= n_out,\n",
    "                    n_in=n_in)\n",
    "loss = loss(y, t)\n",
    "train_step = training(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computational Graph without Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 500\n",
    "batch_size = 10\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "history= {'val_loss': []}\n",
    "n_batches = N_train // batch_size\n",
    "early_stopping = ut.EarlyStopping(patience=100, verbose=1)\n",
    "for epoch in range(epochs):\n",
    "    X_, Y_ = shuffle(X_train, Y_train)\n",
    "    sess.run(train_step, feed_dict={\n",
    "        x: X_[start:end],\n",
    "        t: Y_[start:end],\n",
    "        n_batch: N_train\n",
    "        })\n",
    "    val_loss = loss.eval(session=sess, feed_dict={\n",
    "        x: X_validation,\n",
    "        t: Y_validation,\n",
    "        n_batch: N_validation\n",
    "    })\n",
    "    history['val_loss'].append(val_loss)\n",
    "    print('epoch:', epoch, ' validation loss: ', val_loss)\n",
    "    #Early Stoapping\n",
    "    if early_bstopping.validate(val_loss):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truncate = maxlen\n",
    "Z = X[:1]\n",
    "original = [f[i] for i in range(maxlen)]\n",
    "predicted = [None for i in range(maxlen)]\n",
    "\n",
    "for i in range(length_of_sequences -maxlen +1):\n",
    "    z_ = Z[-1:]\n",
    "    y_ = y.eval(session=sess, feed_dict ={x: Z[-1:],\n",
    "                                          n_batch: 1})\n",
    "    sequence_ = np.concatenate((z_.reshape(maxlen, n_in)[1:], y_), axis=0)\\\n",
    "                               .reshape(1, maxlen, n_in)\n",
    "    Z = np.append(Z, sequence_, axis=0)\n",
    "    predicted.append(y_.reshape(-1))\n",
    "\n",
    "plt.rc('font', family='serif')\n",
    "plt.figure()\n",
    "plt.plot(toy_problem(T, ampl=0), linestyle='dotted', color='#aaaaaa')\n",
    "plt.plot(original, linestyle='dashed', color='black')\n",
    "plt.plot(predicted, color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(cell_output, state) = cell(x[:, 0, :], state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('RNN'):\n",
    "    for t in range(maxlen):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For simplicty reasons, let us first implement a function that only has 2 lags\n",
    "U = weight_variable([1, 1])\n",
    "W = weight_variable([1, ])\n",
    "\n",
    "h2 = tf.tanh(U)\n",
    "V = weight_variable([n_hidden, 1])\n",
    "c = bias_variable(1)\n",
    "y = tf.matmul(h2, V) + c"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
